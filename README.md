# ğŸ“Š Mapa Carreira em Dados

Projeto criado para responder Ã  pergunta:

> **Quais informaÃ§Ãµes sÃ£o relevantes para quem deseja iniciar ou migrar para a Ã¡rea de Dados?**

A partir de uma base pÃºblica sobre salÃ¡rios e perfis profissionais da Ã¡rea, este projeto percorre **todo o ciclo de um projeto real de dados**:

**ExtraÃ§Ã£o â†’ Limpeza â†’ TransformaÃ§Ã£o â†’ AnÃ¡lise â†’ VisualizaÃ§Ã£o â†’ Deploy**

A entrega final Ã© um **dashboard interativo em Streamlit**, publicado na nuvem.

ğŸ”— **Acesse a aplicaÃ§Ã£o online:** *(coloque aqui o link do seu deploy)*

---

## ğŸ¯ Objetivo do Projeto

Demonstrar, na prÃ¡tica, como um projeto de dados Ã© construÃ­do desde os dados brutos atÃ© a geraÃ§Ã£o de valor em forma de dashboard analÃ­tico.

Este projeto tambÃ©m serve como base para evoluÃ§Ãµes arquiteturais mais avanÃ§adas, como SQL, Data Warehouse e Modelagem Dimensional.

---

## ğŸ§± Arquitetura do Projeto â€” v1.0 (Atual)

Nesta primeira versÃ£o, a arquitetura utiliza um pipeline direto com Pandas:

```
Dados brutos â†’ Pandas (ETL) â†’ CSV tratado â†’ Streamlit â†’ Dashboard
```

Essa abordagem Ã© simples, funcional e muito comum em projetos iniciais de anÃ¡lise de dados.

---

## ğŸš€ EvoluÃ§Ã£o Planejada â€” v2.0

A prÃ³xima etapa do projeto consiste em evoluir essa arquitetura para um modelo mais profissional utilizando:

- Banco de dados SQL para persistÃªncia
- SeparaÃ§Ã£o entre ingestÃ£o, transformaÃ§Ã£o e consumo
- Modelagem Dimensional (Star Schema)
- Consultas analÃ­ticas diretamente do banco no Streamlit

O objetivo Ã© demonstrar **por que a abordagem com Pandas funciona**, mas **por que uma arquitetura com banco de dados Ã© mais escalÃ¡vel e organizada**.

---

## âœ¨ Funcionalidades

- Limpeza e padronizaÃ§Ã£o de dados com Pandas
- Tratamento de variÃ¡veis categÃ³ricas e quantitativas
- TraduÃ§Ã£o e organizaÃ§Ã£o das informaÃ§Ãµes da base
- AnÃ¡lise exploratÃ³ria dos dados
- Dashboards interativos com filtros dinÃ¢micos
- Deploy em nuvem com Streamlit Cloud

---

## ğŸ—‚ï¸ Estrutura do RepositÃ³rio

```
.
â”œâ”€â”€ app.py
â”œâ”€â”€ df_limpo.csv
â”œâ”€â”€ etl_colab.ipynb
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ img/
â””â”€â”€ README.md
```

---

## âœ… PrÃ©-requisitos

Para executar o projeto localmente Ã© necessÃ¡rio ter instalado:

- Python 3.10+
- Git

Opcional:
- VSCode ou outro editor de cÃ³digo

---

## ğŸ› ï¸ Como executar localmente

### 1ï¸âƒ£ Clone o repositÃ³rio

```bash
git clone https://github.com/heldjow/ImersaoDadosAlura
cd ImersaoDadosAlura
```

### 2ï¸âƒ£ Crie o ambiente virtual

Linux / Mac:

```bash
python3 -m venv .venv
source .venv/bin/activate
```

Windows:

```bash
python -m venv .venv
.venv\Scripts\activate
```

### 3ï¸âƒ£ Instale as dependÃªncias

```bash
pip install -r requirements.txt
```

### 4ï¸âƒ£ Execute a aplicaÃ§Ã£o

```bash
streamlit run app.py
```

---

## ğŸŒ Deploy da AplicaÃ§Ã£o

O deploy pode ser feito gratuitamente utilizando o **Streamlit Cloud**:

1. Acesse: https://streamlit.io/cloud
2. Conecte sua conta do GitHub
3. Selecione este repositÃ³rio
4. Informe o arquivo `app.py` como ponto de entrada

---

## ğŸ§  O que este projeto demonstra

Este projeto evidencia conhecimentos em:

- Processo completo de ETL com Pandas
- AnÃ¡lise exploratÃ³ria de dados
- ConstruÃ§Ã£o de dashboards analÃ­ticos
- Deploy de aplicaÃ§Ãµes de dados
- OrganizaÃ§Ã£o de projeto e versionamento
- Base para evoluÃ§Ã£o para arquitetura SQL + Data Warehouse

---

## ğŸ”– Versionamento do Projeto

- **v1.0** â€” Pipeline direto com Pandas e CSV tratado
- **v2.0 (em desenvolvimento)** â€” PersistÃªncia em SQL + Modelagem Dimensional

---

## ğŸ“Œ ObservaÃ§Ã£o

Todo o processo de tratamento dos dados pode ser visualizado no notebook disponÃ­vel no repositÃ³rio (`etl_colab.ipynb`).

